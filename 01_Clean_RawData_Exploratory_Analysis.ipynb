{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9441a046",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "     <b>Import Modules Needed</b> <i>(need pandas >= 1.2 and python >= 3.9.0 for all the data cleaning techniques to work)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import os\n",
    "import sweetviz as sv\n",
    "import numpy as np\n",
    "import dtale\n",
    "import cudf\n",
    "import dask_cudf\n",
    "from pandasql import sqldf\n",
    "\n",
    "#!pip install git+https://github.com/innovationOUtside/fstring-magic.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext fstring_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd3b747",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Jupyter Plumbing</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779fe14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINDOWS - get IP address of running Ubuntu instance\n",
    "# Run an admin elevated powershell instance (not ubuntu VM)\n",
    "# netsh interface portproxy add v4tov4 listenport=40000 listenaddress=0.0.0.0 connectport=40000 connectaddress=172.21.240.230\n",
    "# This will open up a port that the dtale package between local windows machine and the Ubuntu VM need to display correctly\n",
    "!ifconfig\n",
    "# netsh interface portproxy add v4tov4 listenport=40000 listenaddress=0.0.0.0 connectport=40000 connectaddress=172.21.240.230\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f21b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load C:\\users\\derek\\.jupyter\\startup.py\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "pd.options.display.max_seq_items = 500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab9734f",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border-width:0;color:black;background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ef24e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Find CSV Files in working dir</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a87745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csvStore = os.path.join(os.getcwd(),'__csvStore' )\n",
    "csvlist = []\n",
    "for file in enumerate(os.listdir(csvStore)):\n",
    "    if file[1].endswith(\".csv\"):\n",
    "        csvlist.append(os.path.join(str(csvStore), file[1]))\n",
    "        print(os.path.join(str(csvStore), file[1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22caa8e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Import the raw data</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21d325",
   "metadata": {},
   "source": [
    "I learned through manual trial and error many different data issues when trying to import the csv <br>\n",
    "The main issue was with datetimes, and columns recognized as containing mixed data types. <br>\n",
    "Some columns can be converted during import but other must be coerced after <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = 'orig_data2.csv'\n",
    "list(enumerate(csvlist))\n",
    "csvlist[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80fd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csvlist[4], na_values = ['IGNORED', '-', 'UNKNOWN', 'UK - OTHER UNKNOWN', 'UK - UNKNOWN'], dtype = {'ceas_ascode': object, 'M1322_NBR_PRSULC_STG1':object})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3992ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fstring\n",
    "__There are {len(df.columns)} columns, in the df__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde9ab93",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Create SweetViz EDA Report</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca15465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzing the dataset\n",
    "hospice_death_report = sv.analyze(df, pairwise_analysis = 'off')\n",
    "#display the report\n",
    "hospice_death_report.show_html('cleaned_hospice_dead.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de039c7",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border-width:0;color:black;background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee2e3b",
   "metadata": {},
   "source": [
    "# Part 1 Cleanup of full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e2083e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <b>Manually Clean up Data (remove cols) based on SweetViz report</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b35e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(df.columns[np.r_[3, 5, 14, 15, 36, 47:70, 87:94, 100:104, 105:107, 122:129, 136, 138:149, 151, 168, 178:184, 192:194, 195:198, 201, 204:211, 212:218, 219, 221:223, 224:229, 230:232, 240:261, 261:266]], axis = 1)\n",
    "                                    \n",
    "#df_clean.columns\n",
    "\n",
    "\n",
    "# REMOVE COLS WITH ONLY NAN\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe0c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fstring\n",
    "__There are {len(df.columns)} columns remaining if we simply eliminate columns with 100% null values, or {len(df_clean.columns)} based on my manual removal process__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d606686",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <b>Compare manual elimination of empty columns via SweetViz to pandas automatic removal</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.columns).difference(df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c95615",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop((df.columns).difference(df_clean.columns), axis = 1)\n",
    "len(df.columns)\n",
    "len(df.columns) == len(df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac07b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fstring\n",
    "__We can remove these columns even though they are not strictly NAN. They are majority NAN and are not useful to the analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d27d19",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Find Columns with Dates and convert them to datetime type</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212933ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_w_dates = df.columns[(df.columns.str.contains('DT', case=False) | df.columns.str.contains('date', case=False) | df.columns.str.contains('OFEPISODE', case=False))] \n",
    "df[cols_w_dates] = df[cols_w_dates].apply(pd.to_datetime)\n",
    "cols_w_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58354bdd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Find Columns that contain mixed data types to investigate for possible data quality issues</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mixed_dtypes := {c: dtype for c in df.columns if (dtype := pd.api.types.infer_dtype(df[c])).startswith(\"mixed\")}:\n",
    "    raise TypeError(f\"Dataframe has one more mixed dtypes: {mixed_dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f892cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Run in Linux pd.read_csv was detecting mixed datatype differently than windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Coerce bad columns to int dtype\n",
    "# for col in ['M1311_NSTG_CVRG_SOCROC_E2','M1322_NBR_PRSULC_STG1', 'M2200_THER_NEED_NBR']:\n",
    "#   df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "         \n",
    "for col in ['M1322_NBR_PRSULC_STG1']:\n",
    "   df[col] = pd.to_numeric(df[col], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive IDs\n",
    "df.columns[:26]\n",
    "colsMeta = df.columns[:26]\n",
    "# OASIS Factors\n",
    "df.columns[26:]\n",
    "colsOASIS = df.columns[26:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2040678e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <b>Percentage of Null Values by Column to see if there are errors or we can eliminate unhelpful columns</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbc0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[:,colsOASIS].isnull().sum()/len(df.loc[:,colsOASIS])).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eafe464",
   "metadata": {},
   "source": [
    "> Since we previously eliminated completely empty columns we should not expect to see empty columns here. We see the columns ranked by degree of missing values <BR>\n",
    "  Prime candidates for elimination are columns with 90% or greater nulls. We need both training and testing sets to be populated with the same metrics or there is no apples-apples comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb04754",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border-width:0;color:black;background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f0825",
   "metadata": {},
   "source": [
    "# Part 2 Cleanup of Alive vs Dead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384dbe97",
   "metadata": {},
   "source": [
    "After cleaning up the dataset as a whole, we should dive deeper and cleanup based on the two main types of patients: Alive vs Dead which end up being training and testing sets.  We need a common set of features between both of these groups or we wont have an Apples to Apples comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b078c244",
   "metadata": {},
   "source": [
    "<mark>The dataset contains 3 Patient Groups (Disposition ID): Died in Hospice, Died in Home Health Care, Alive so we now need to move to the 2nd stage of EDA and that is getting a clean deadpatients list</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8c42d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <b>% of null values by Disposition ID</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bef39cc",
   "metadata": {},
   "source": [
    "# Missing Values (Pct Total) for Disposition 3 Patients (Hospice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50412e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[:,colsOASIS][df['DispositionId']==3].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==3])).sort_values(ascending=False)\n",
    "mask3 = (df.loc[:,colsOASIS][df['DispositionId']==3].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==3])>=.75).sort_values(ascending=False)\n",
    "#df.loc[:, ~mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,colsOASIS].loc[:, mask3].columns\n",
    "mask3_sr = df.loc[:,colsOASIS].loc[:, mask3].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5437f3fe",
   "metadata": {},
   "source": [
    "# Missing Values (Pct Total) for Disposition 2 Patients (HHG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60482aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[:,colsOASIS][df['DispositionId']==2].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==2])).sort_values(ascending=False)\n",
    "mask2 = (df.loc[:,colsOASIS][df['DispositionId']==2].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==2])>=.75).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5331687",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,colsOASIS].loc[:, mask2].columns\n",
    "mask2_sr = df.loc[:,colsOASIS].loc[:, mask2].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec7edf",
   "metadata": {},
   "source": [
    "# Factors Missing All Values for All Dead Patients (Disposition 2 and 3 combined) - We can Eliminate from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(mask3_sr).difference(mask2_sr)\n",
    "#(mask2_sr).difference(mask3_sr)\n",
    "#mask2_sr.union(mask3_sr)\n",
    "#mask2_sr.intersection(mask3_sr)\n",
    "len(mask2_sr.union(mask3_sr))\n",
    "mask2_sr.union(mask3_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a36be29",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e089f9d",
   "metadata": {},
   "source": [
    "# There are no fields completley null for the alive patients cohort except there ae some close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e926104",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[:,colsOASIS][df['DispositionId']==1].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==1])).sort_values(ascending=False)\n",
    "mask1 = (df.loc[:,colsOASIS][df['DispositionId']==1].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==1])>=.75).sort_values(ascending=False)\n",
    "#mask1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigmask = (mask2_sr.intersection(mask3_sr)).intersection(df.loc[:,colsOASIS].loc[:, mask1].columns)\n",
    "#bigmask = (mask2_sr.union(mask3_sr)).intersection(df.loc[:,colsOASIS].loc[:, mask1].columns)\n",
    "bigmask = (mask2_sr.union(mask3_sr)).union(df.loc[:,colsOASIS].loc[:, mask1].columns)\n",
    "bigmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b285e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1-(df[(df['DispositionId']==2) | (df['DispositionId']==3) ].isnull().sum())/len(df[(df['DispositionId']==2) + (df['DispositionId']==3)])).sort_values(ascending=False)\n",
    "(df.loc[:,colsOASIS][(df['DispositionId']==2) | (df['DispositionId']==3) ].isnull().sum()/len(df.loc[:,colsOASIS][(df['DispositionId']==2) + (df['DispositionId']==3)])).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d8cece",
   "metadata": {},
   "source": [
    "# Depending on the formula we can wither see True = Column is above threshold, or True if Column is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d1ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullalive = (1-(df.loc[:,colsOASIS][df['DispositionId']==1].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==1]))>=.90).sort_values(ascending=False)\n",
    "emptyalive = (df.loc[:,colsOASIS][df['DispositionId']==1].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==1])>=.90).sort_values(ascending=False)\n",
    "emptyalive\n",
    "maskfilter1 = emptyalive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eed776",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldead = ((1-(df.loc[:,colsOASIS][(df['DispositionId']==2) | (df['DispositionId']==3) ].isnull().sum())/len(df.loc[:,colsOASIS][(df['DispositionId']==2) + (df['DispositionId']==3)]))>=.90).sort_values(ascending=False)\n",
    "emptydead = (((df.loc[:,colsOASIS][(df['DispositionId']==2) | (df['DispositionId']==3) ].isnull().sum())/len(df.loc[:,colsOASIS][(df['DispositionId']==2) + (df['DispositionId']==3)]))>=.90).sort_values(ascending=False)\n",
    "emptydead\n",
    "maskfilter23 = emptydead #((1-(df[(df['DispositionId']==2) | (df['DispositionId']==3) ].isnull().sum())/len(df[(df['DispositionId']==2) + (df['DispositionId']==3)]))==1).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6906701",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[:,colsOASIS].loc[:, maskfilter1].columns)\n",
    "(df.loc[:,colsOASIS].loc[:, maskfilter1].columns)\n",
    "len(df.loc[:,colsOASIS].loc[:, maskfilter23].columns)\n",
    "(df.loc[:,colsOASIS].loc[:, maskfilter23].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len((df.loc[:,colsOASIS].loc[:, maskfilter1].columns).intersection(df.loc[:,colsOASIS].loc[:, maskfilter23].columns))\n",
    "(df.loc[:,colsOASIS].loc[:, maskfilter1].columns).intersection(df.loc[:,colsOASIS].loc[:, maskfilter23].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e32d51",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <b>Dropping Columns that are NULL for Dead Patients</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2339133",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <b>Dropping Columns with too many null values across Dead Patients (Dispo 2 and Dispo 3)</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b81863",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldrop = (df.loc[:,colsOASIS].loc[:, maskfilter23].columns)[:-1].union(bigmask)\n",
    "len(finaldrop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ffae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(finaldrop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b40b9cf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Export Cleaned DataSet</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d7e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv((csvStore+'/cleaned_data.csv'), sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39755576",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>EDF for our final Factor List</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzing the dataset\n",
    "high_level_cleaned = sv.analyze(df, pairwise_analysis = 'off')\n",
    "#display the report\n",
    "high_level_cleaned .show_html('high_level_cleaned.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1ece8",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border-width:0;color:black;background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a37f071",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "    <b>Tools to Filter DF and understand the dataset</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b53bf5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "    <b>Enumerate the columns to help to more quickly ID them</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6538632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = pd.DataFrame(enumerate(df.columns.values.tolist())).set_index(0)\n",
    "column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed1510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e669a05",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "    <b> Filter Tool to find contents of specific cells</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa16533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[13,107] # add rows if i want to find a specific cell\n",
    "df.iloc[13:14,:10] # add rows if i want to find a specific cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e440811e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "    <b>Eliminate Columns with only 1 distinct value</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1053b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[]\n",
    "for col in df.columns:\n",
    "    if len(df[col].unique()) >= 1 and len(df[col].unique()) <= 3:\n",
    "        cols.append(col)\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72650d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ea23e",
   "metadata": {},
   "source": [
    "The number of unique values in a column provide insight into the nature of the column.<br>\n",
    "The OASIS data is standardized so there are only a few responses the nurses must choose.<br>\n",
    "pa_id will have many more unique value, followed by episode id, all the way to a primary key with a unique value for each row<br>\n",
    "<br>\n",
    "We Eliminated Columns From Dead Patients if all the values were missing.<br>\n",
    "There is no Point in keeping these columns for the independent variables either"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c1ed3",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border-width:0;color:black;background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2490b40",
   "metadata": {},
   "source": [
    "# Part 2.1 Remove Duplicate Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b96bf",
   "metadata": {},
   "source": [
    "# START HERE w Base Case dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f55e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csvStore+'/cleaned_data.csv', dtype = {'ceas_ascode': object, 'M1322_NBR_PRSULC_STG1':object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mixed_dtypes := {c: dtype for c in df.columns if (dtype := pd.api.types.infer_dtype(df[c])).startswith(\"mixed\")}:\n",
    "    raise TypeError(f\"Dataframe has one more mixed dtypes: {mixed_dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_w_dates = df.columns[(df.columns.str.contains('DT', case=False) | df.columns.str.contains('date', case=False) | df.columns.str.contains('OfEpisode', case=False)  )] \n",
    "df[cols_w_dates] = df[cols_w_dates].apply(pd.to_datetime)\n",
    "\n",
    "\n",
    "\n",
    "cols_w_dates = cols_w_dates.union(df.columns[(df.columns.str.contains('DAYS', case=False))])\n",
    "\n",
    "cols_w_dates = ['epi_SocDate', 'epi_StartOfEpisode', 'epi_EndOfEpisode', 'epi_DischargeDate', 'M0906_DC_TRAN_DTH_DT', 'M0090_INFO_COMPLETED_DT', 'cedd_dateofdeath', 'DaysToDeath']\n",
    "\n",
    "\n",
    "firstcols = [ 'DispositionId', 'pa_id', 'year_born', 'pa_gender', 'epi_id', 'ceo_id']\n",
    "first_cols = firstcols+cols_w_dates\n",
    "\n",
    "move_columns = first_cols + (df.columns.drop(first_cols).tolist())\n",
    "df = df[move_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb01470",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "  <strong>Create a GPU version of DFF for faster processing</strong> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6289f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = cudf.DataFrame(df)\n",
    "len(dff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03093171",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <b>Create Filters that remove the primary keys</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffcols3 = dff.columns.difference(['Unnamed: 0', 'ceo_HIPPS', 'ceo_HHRG', 'ceo_id'])\n",
    "df_deduped3 = dff.drop_duplicates(subset=dffcols3)\n",
    "df_deduped3.shape # This is the same because it has keep by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a061e8cd",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <b>This makes sure that when removing duplicates we keep the rows that have HIPPS codes</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_indx = (dff.sort_values(by=\"ceo_HIPPS\", na_position='last').drop_duplicates(subset=dffcols3, keep='first')).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d63ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_indx = dff.loc[uniq_indx]\n",
    "len(uniq_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235543ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(uniq_indx.to_pandas().head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0897d972",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Export De-Duped Dataset</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_indx.to_pandas().to_csv(csvStore+'/deduped_complete.csv', sep=',', encoding='utf-8', index=False)\n",
    "dff = uniq_indx\n",
    "df = dff.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a327dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)\n",
    "len(dff)\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3eb7f9",
   "metadata": {},
   "source": [
    "# Part 3 - Get Patient Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.groupby('DispositionId').agg({'pa_id': 'nunique'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ef1c6",
   "metadata": {},
   "source": [
    "# This group of patients has more than 1 Disposition ID which was discovered when counting the number of unique patient id's in the entire dataset vs the number of unique patients with each disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dff.pa_id.unique())\n",
    "grp = dff.groupby('pa_id').nunique()['DispositionId'].apply(lambda g: g>1)\n",
    "len(grp[grp].index)\n",
    "grp[grp].index\n",
    "dff[dff['pa_id'].isin(grp[grp].index)].reset_index(drop=True).to_csv(csvStore+'/du.csv', index=False)\n",
    "len(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d2fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(dff[dff['pa_id'].isin(grp[grp].index)].to_pandas().reset_index(drop=True).sort_values(by=['pa_id', 'DispositionId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5007c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Disposition = pd.read_csv(csvStore+'/du.csv', dtype = {'ceas_ascode': object, 'M1322_NBR_PRSULC_STG1':object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f27aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mixed_dtypes := {c: dtype for c in df_Disposition.columns if (dtype := pd.api.types.infer_dtype(df_Disposition[c])).startswith(\"mixed\")}:\n",
    "    raise TypeError(f\"Dataframe has one more mixed dtypes: {mixed_dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b15bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "cols_w_dates = df_Disposition.columns[(df_Disposition.columns.str.contains('DT', case=False) | df_Disposition.columns.str.contains('date', case=False) | df_Disposition.columns.str.contains('OfEpisode', case=False)  )] \n",
    "df_Disposition[cols_w_dates] = df_Disposition[cols_w_dates].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df_Disposition.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2dc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''SELECT pa_id, min(epi_SocDate) as SOC, max(epi_DischargeDate) as final_dschg\n",
    "           FROM df_Disposition \n",
    "           GROUP BY pa_id\n",
    "           HAVING (JULIANDAY(final_dschg) - JULIANDAY(SOC) < 365)\n",
    "            '''\n",
    "deaddupes = sqldf(query)\n",
    "deaddupeset = set(deaddupes.pa_id)\n",
    "\n",
    "\n",
    "querya = '''SELECT pa_id, min(epi_SocDate) as SOC, max(epi_DischargeDate) as final_dschg\n",
    "           FROM df_Disposition \n",
    "           GROUP BY pa_id\n",
    "           HAVING (JULIANDAY(final_dschg) - JULIANDAY(SOC) > 365)\n",
    "            '''\n",
    "\n",
    "            \n",
    "alivedupes = sqldf(querya)\n",
    "alivedupeset = set(alivedupes.pa_id)\n",
    "\n",
    "dtale.show(df_Disposition[df_Disposition.pa_id.isin(deaddupeset)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee8a264",
   "metadata": {},
   "source": [
    "# Remove Patients with Duplicate Dispositions in name of cleanliness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c023ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dff = dff[~(dff['pa_id'].isin(grp[grp].index) & (dff.DispositionId == 1)) ]\n",
    "dtale.show(dff.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98763d26",
   "metadata": {},
   "source": [
    "## Eliminate rows and Patients where the SOC date doesn't equal the 1st episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63251412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dff.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248040b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_Patient_list1 = set(df.pa_id[((df.DispositionId == 1) & (df['epi_SocDate'] == df['epi_StartOfEpisode']))])#.to_list())\n",
    "#df_Patient_list1 = set(df.pa_id[(((df.DispositionId == 1) | (df.DispositionId == 2)) & (df['epi_SocDate'] == df['epi_StartOfEpisode']))])#.to_list())\n",
    "df_Patient_list2 = set(df.pa_id[((df.DispositionId == 1) & (df['epi_SocDate'] != df['epi_StartOfEpisode']))])#.to_list())\n",
    "#df_Patient_list2 = set(df.pa_id[(((df.DispositionId == 1) | (df.DispositionId == 2)) & (df['epi_SocDate'] != df['epi_StartOfEpisode']))])#.to_list())\n",
    "df_Patient_list3 = set(df.pa_id[((df.DispositionId == 1) & (df['epi_StartOfEpisode'] <= (df['epi_SocDate']) + pd.Timedelta(120, unit='D')  ))])\n",
    "df_Patient_list4 = set(df.pa_id[(((df.DispositionId == 2) | (df.DispositionId == 3)) & (df['epi_SocDate'] == df['epi_StartOfEpisode']))])#.to_list())\n",
    "df_Patient_list5 = set(df.pa_id[(((df.DispositionId == 2) | (df.DispositionId == 3)) & (df['epi_SocDate'] != df['epi_StartOfEpisode']))])#.to_list())\n",
    "df_Patient_list6 = set(df.pa_id[((df.DispositionId == 3) & (df['epi_SocDate'] == df['epi_StartOfEpisode']))])#.to_list())\n",
    "df_Patient_list7 = set(df.pa_id[((df.DispositionId == 3) & (df['epi_SocDate'] != df['epi_StartOfEpisode']))])#.to_list())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f\"There are {len(df_Patient_list1)} alive patients whose SOC date matches their first episode date\"\n",
    "f\"There are {len(df_Patient_list2)} alive patients whose SOC date DOES NOT MATCH their first episode date\"\n",
    "\n",
    "\n",
    "f\"There are {len(df_Patient_list3)} alive patients whose SOC date is 120 days earlier than their first episode\"\n",
    "f\"There are {len(df_Patient_list4)} dead HHG patients whose SOC date matches their first episode date\"\n",
    "\n",
    "\n",
    "f\"There are {len(df_Patient_list5)} dead HHG patients whose SOC date matches their first episode date\"\n",
    "f\"There are {len(df_Patient_list6)} dead hospice patients whose SOC date matches their first episode date\"\n",
    "f\"There are {len(df_Patient_list7)} dead hospice patients whose SOC date DOES NOT MATCH their first episode date\"\n",
    "\n",
    "\n",
    "\n",
    "len(df_Patient_list1.intersection(df_Patient_list2))\n",
    "len(df_Patient_list3.intersection(df_Patient_list4))\n",
    "len(df_Patient_list5.intersection(df_Patient_list6))\n",
    "\n",
    "df_SOC = (pd.DataFrame(df_Patient_list6))\n",
    "\n",
    "\n",
    "df_SOC.to_csv(csvStore+'/soc2.csv', sep=',', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf0ab0",
   "metadata": {},
   "source": [
    "> Within each disposition their are a minority of patients who have SOC dates, earlier than their first episode.  Only within the alive patients do we have individual patients with both date types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c4b28f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <b>Get our list of Dead Patients</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ab3b5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Hospice Patients with cedd_dataofdeath within 1 year from Start of Care</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67145a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df[df.DispositionId == 3].head(15))\n",
    "dead_hospice_patients = set(df.pa_id[(df.DispositionId == 3) & (df.DaysToDeath < 366)].to_list())\n",
    "dead_366 = set(df.pa_id[(df.DispositionId == 3) & (df.DaysToDeath >= 366)].to_list())\n",
    "f\"There are {len(dead_hospice_patients)}, patients who died in hospice care less than a year after transferring and {len(dead_hospice_patients)+ len(dead_366)} in total\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6b5b78",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>These 3 Patients Had Days to Death Greater Than 365</b>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ddf830",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospice366 = set(df.pa_id[(df.DispositionId == 3) & (df.DaysToDeath > 365)].to_list())\n",
    "dtale.show(df[['pa_id', 'DaysToDeath', 'pa_gender']][df.pa_id.isin(hospice366)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02591632",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Home Health Patients who Died at home less than 1 year after Starting Care</b>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e09575",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df[(df.DispositionId == 2) & (df.M0100_ASSMT_REASON == '8 - DEATH AT HOME')].head(15))\n",
    "HHP_DeadAtHome = set(df.pa_id[(df.DispositionId == 2) & (df.dcc_desc == 'PATIENT EXPIRED') & (df.dcr_desc == 'PATIENT EXPIRED') & (df.M0100_ASSMT_REASON == '8 - DEATH AT HOME') & (df.M0906_DC_TRAN_DTH_DT <= (df.epi_SocDate + pd.Timedelta(365, unit='D')))].to_list())\n",
    "f\"There are {len(HHP_DeadAtHome)}, HH patients who died at home within 1 year of SOC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HHP_Dead = set(df.pa_id[(df.DispositionId == 2) & (df.dcc_desc == 'PATIENT EXPIRED') & (df.dcr_desc == 'PATIENT EXPIRED') & (df.M0100_ASSMT_REASON == '8 - DEATH AT HOME')].to_list())\n",
    "len(HHP_Dead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c3c92",
   "metadata": {},
   "source": [
    "# There are 22 patients who died at home but took longer than 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(HHP_Dead.intersection(HHP_DeadAtHome))\n",
    "len(HHP_Dead.difference(HHP_DeadAtHome))# Makes sense because one is subset of the other: 484 died at home period, 462 died at home with the time criteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HHP_Dead.difference(HHP_DeadAtHome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30594ad6",
   "metadata": {},
   "source": [
    "### Home Health Care Patients Labeled with both dcr_dsec and dcr_desc Expired but no indication of Death via nurse evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af56369",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df[(df.DispositionId == 2) & (df.M0100_ASSMT_REASON != '8 - DEATH AT HOME')].head(15))\n",
    "HHP_expired = set(df.pa_id[(df.DispositionId == 2) & (df.dcc_desc == 'PATIENT EXPIRED') & (df.dcr_desc == 'PATIENT EXPIRED') & (df.M0100_ASSMT_REASON != '8 - DEATH AT HOME') & (df.M0906_DC_TRAN_DTH_DT <= (df.epi_SocDate + pd.Timedelta(365, unit='D')))].to_list())\n",
    "f\"There are {len(HHP_expired)}, patients who have rows with no death at home\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e1a2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c687b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HHP_expired2 = set(df.pa_id[(((df.DispositionId == 2) | (df.DispositionId == 1)) & (df.dcc_desc == 'PATIENT EXPIRED') & (df.dcr_desc == 'PATIENT EXPIRED') & (df.epi_DischargeDate >= (df.epi_SocDate + pd.Timedelta(365, unit='D'))))].to_list())\n",
    "HHP_expired3 = set(df.pa_id[((df.DispositionId == 1) & (df.epi_DischargeDate >= (df.epi_SocDate + pd.Timedelta(365, unit='D'))))].to_list())\n",
    "\n",
    "f\"There are {len(HHP_expired2)}, patients who have rows with no death at home\"\n",
    "f\"There are {len(HHP_expired3)}, patients who have rows with no death at home\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94861ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Out of the 821 patients who have assessments with no indication of heath at home, 754 of them never did at all but 67 did.\n",
    "#This means that 67 patients meet both criteria: in other words they have a death at home note, but also additional rows\n",
    "# The 754 have no indication of a death at home\n",
    "\n",
    "len(HHP_DeadAtHome.intersection(HHP_expired))\n",
    "len(HHP_expired.intersection(HHP_DeadAtHome))\n",
    "len(HHP_expired.union(HHP_DeadAtHome))\n",
    "\n",
    "len(HHP_expired.difference(HHP_DeadAtHome)) # 754 + 67 = 821 patients who didnt\n",
    "len(HHP_DeadAtHome.difference(HHP_expired)) # 395 + 67 = 462 HH patients who are confirmed died at home in less than 1 year\n",
    "#sett = HHP_DeadAtHome.difference(HHP_expired)\n",
    "#sett = HHP_expired.difference(HHP_DeadAtHome)\n",
    "sett = HHP_expired.intersection(HHP_DeadAtHome)\n",
    "\n",
    "\n",
    "\n",
    "died_at_home = HHP_DeadAtHome.difference(HHP_expired)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e8fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df[['pa_id', 'DispositionId', 'DaysToDeath', 'pa_gender', 'dcc_desc', 'dcr_desc', 'M0906_DC_TRAN_DTH_DT', 'epi_SocDate' ]][df.pa_id.isin(sett)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ddd6e1",
   "metadata": {},
   "source": [
    "## Get combined Set of Dead Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "deadlistset = dead_hospice_patients.union(died_at_home)\n",
    "deadlist = pd.DataFrame(deadlistset)\n",
    "f\"There are {len(deadlist)}, patients who are reliably confirmed dead within 1 year of SOC, either in hospice, or at home, \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4686620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dead = dff[dff['pa_id'].isin(deadlistset)]\n",
    "df_dead.info()\n",
    "dtale.show(df_dead.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e7042",
   "metadata": {},
   "outputs": [],
   "source": [
    "len((dff[dff.DispositionId == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.groupby('DispositionId').agg({'pa_id': 'nunique'})\n",
    "df_dead.groupby('DispositionId').agg({'pa_id': 'nunique'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a48d318",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border-width:0;color:black;background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eab97f7",
   "metadata": {},
   "source": [
    "# Newer Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qHospiceDead = '''SELECT pa_id, dcc_desc, dcr_desc, DispositionId, DaysToDeath \n",
    "           FROM df \n",
    "           WHERE DaysToDeath < 365'''\n",
    "\n",
    "qHHDead = '''SELECT pa_id, dcc_desc, dcr_desc, DispositionId, DaysToDeath, JULIANDAY(epi_DischargeDate) -  JULIANDAY(epi_SocDate) as INT\n",
    "           FROM df \n",
    "           WHERE DispositionID != 3 AND (dcc_desc = 'PATIENT EXPIRED' and dcr_desc = 'PATIENT EXPIRED' and INT < 365)'''\n",
    "\n",
    "\n",
    "\n",
    "hospiceDead = sqldf(qHospiceDead)\n",
    "HHDead = sqldf(qHHDead)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosDeadset = set(hospiceDead.pa_id)\n",
    "HHDeadset = set(HHDead.pa_id)\n",
    "deadlistset = hosDeadset.union(HHDeadset).union(deaddupeset)\n",
    "\n",
    "df_dead = df[df.pa_id.isin(deadlistset)]\n",
    "f\"There are {len(deadlistset)}, patients who died in less than 1 year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc031ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtale.show(df_dead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543c627e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <b>Export Dataset with Bad Columns Removed and Dead Patients with more than 365 days removed</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89467961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dead.to_csv(csvStore+'/dead_patients_final.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d9f1f6",
   "metadata": {},
   "source": [
    "# Get Patients who have lived longer than 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0765cc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HHP_dead.intersection(HHP_alive)\n",
    "len(HHP_dead.intersection(HHP_alive))\n",
    "\n",
    "\n",
    "dtale.show(df[df.pa_id.isin(HHP_dead.intersection(HHP_alive))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11f4e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HHP_alive = set(df.pa_id[((df.epi_DischargeDate) >= ((df.epi_SocDate | df.cedd_dateofdeath) + pd.Timedelta(365, unit='D')) ) ].to_list())\n",
    "\n",
    "query = '''SELECT pa_id, JULIANDAY(cedd_dateofdeath) -  JULIANDAY(epi_SocDate) as INT,  JULIANDAY(epi_DischargeDate) -  JULIANDAY(epi_SocDate) as INT2 \n",
    "           FROM df \n",
    "           WHERE INT > 365 or INT2 > 365 or DaysToDeath > 365'''\n",
    "\n",
    "alive = sqldf(query)\n",
    "\n",
    "HHP_alive = set(alive.pa_id).union(alivedupeset)\n",
    "HHP_alive = set(HHP_alive)\n",
    "\n",
    "df_alive = df[df.pa_id.isin(HHP_alive)]\n",
    "\n",
    "f\"There are only {len(HHP_alive)}, patients who have lived longer than 1 year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtale.show(df[((df.DispositionId == 1) & (df.epi_DischargeDate >= (df.epi_SocDate + pd.Timedelta(365, unit='D'))))])\n",
    "dtale.show(df[df.pa_id.isin(HHP_alive)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d4dc9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Export Alive List</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "alivelist = pd.DataFrame(HHP_alive)\n",
    "df_alive.to_csv(csvStore+'/alive_patients_final.csv', sep=',', encoding='utf-8', index=False)\n",
    "f\"There are {len(alivelist)}, patients in the dataset who lived longer than 1 year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd2f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "neither = deadlistset.union(HHP_alive)    \n",
    "conditions = [df['pa_id'].isin(HHP_alive), df['pa_id'].isin(deadlistset), (~df['pa_id'].isin(neither))]\n",
    "values = ['0', '1', None]\n",
    "df.insert(2, \"mortality\", np.select(conditions, values))                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d726184",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df.head(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('mortality').agg({'pa_id': 'nunique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7895b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df[~df['mortality'].isnull()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907c2401",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <b>Remove Weird Rows where Patient number differ for hospice transfers</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b747734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('pa_id').agg({'ceo_id': 'nunique'}).sort_values('ceo_id', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82afbec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupby('ceo_id').agg({'pa_id': 'nunique'}).sort_values('pa_id', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visits = (df.groupby('ceo_id').agg({'pa_id': 'nunique'}).sort_values('pa_id', ascending=False).pa_id==2).reset_index()\n",
    "visits = df_visits.ceo_id[df_visits.pa_id==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e723ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88baa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[~((df.ceo_id.isin(visits)) & (df.DispositionId != 3))])\n",
    "df = df[~((df.ceo_id.isin(visits)) & (df.DispositionId != 3))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dcde3a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <b>Final Data Sets</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aeabd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[~df['mortality'].isnull()]\n",
    "df_eliminated = df[df['mortality'].isnull()]\n",
    "df_final.to_csv(csvStore+'/final.csv', sep=',', encoding='utf-8', index=False)\n",
    "df_eliminated.to_csv(csvStore+'/eliminated.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54c56c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rapids-22.02]",
   "language": "python",
   "name": "conda-env-rapids-22.02-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
