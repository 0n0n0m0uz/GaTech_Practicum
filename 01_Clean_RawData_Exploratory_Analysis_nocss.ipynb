{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9441a046",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "     <b>Import Modules Needed</b> <i>(need pandas >= 1.2 and python >= 3.9.0 for all the data cleaning techniques to work)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import os\n",
    "import sweetviz as sv\n",
    "import numpy as np\n",
    "import dtale\n",
    "import cudf\n",
    "import dask_cudf\n",
    "from pandasql import sqldf\n",
    "\n",
    "#!pip install git+https://github.com/innovationOUtside/fstring-magic.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext fstring_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd3b747",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Jupyter Plumbing</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779fe14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINDOWS - get IP address of running Ubuntu instance\n",
    "# Run an admin elevated powershell instance (not ubuntu VM)\n",
    "# netsh interface portproxy add v4tov4 listenport=40000 listenaddress=0.0.0.0 connectport=40000 connectaddress=172.21.240.230\n",
    "# This will open up a port that the dtale package between local windows machine and the Ubuntu VM need to display correctly\n",
    "#!ifconfig\n",
    "# netsh interface portproxy add v4tov4 listenport=40000 listenaddress=0.0.0.0 connectport=40000 connectaddress=172.21.240.230\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47820ed",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Check Dtale port</b>\n",
    "</div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b16d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f21b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load C:\\users\\derek\\.jupyter\\startup.py\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "pd.options.display.max_seq_items = 500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ef24e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Find CSV Files in working dir</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a87745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csvStore = os.path.join(os.getcwd(),'__csvStore' )\n",
    "csvlist = []\n",
    "for file in enumerate(os.listdir(csvStore)):\n",
    "    if file[1].endswith(\".csv\"):\n",
    "        csvlist.append(os.path.join(str(csvStore), file[1]))\n",
    "        print(os.path.join(str(csvStore), file[1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22caa8e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Import the raw data</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21d325",
   "metadata": {},
   "source": [
    "I learned through manual trial and error many different data issues when trying to import the csv <br>\n",
    "The main issue was with datetimes, and columns recognized as containing mixed data types. <br>\n",
    "Some columns can be converted during import but other must be coerced after <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = 'orig_data2.csv'\n",
    "list(enumerate(csvlist))\n",
    "csvlist[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80fd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csvlist[5], na_values = ['IGNORED', '-', 'UNKNOWN', 'UK - OTHER UNKNOWN', 'UK - UNKNOWN'], dtype = {'ceas_ascode': object, 'M1322_NBR_PRSULC_STG1':object})\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3992ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fstring\n",
    "__There are {len(df.columns)} columns, in the df__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde9ab93",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Create SweetViz EDA Report</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca15465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzing the dataset\n",
    "# hospice_death_report = sv.analyze(df, pairwise_analysis = 'off')\n",
    "#display the report\n",
    "# hospice_death_report.show_html('cleaned_hospice_dead.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee2e3b",
   "metadata": {},
   "source": [
    "# Part 1 Cleanup of full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e2083e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <b>Manually Clean up Data (remove cols) based on SweetViz report</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b35e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(df.columns[np.r_[3, 5, 14, 15, 36, 47:70, 87:94, 100:104, 105:107, 122:129, 136, 138:149, 151, 168, 178:184, 192:194, 195:198, 201, 204:211, 212:218, 219, 221:223, 224:229, 230:232, 240:261, 261:266]], axis = 1)\n",
    "                                    \n",
    "#df_clean.columns\n",
    "\n",
    "\n",
    "# REMOVE COLS WITH ONLY NAN\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe0c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fstring\n",
    "__There are {len(df.columns)} columns remaining if we simply eliminate columns with 100% null values, or {len(df_clean.columns)} based on my manual removal process__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d606686",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <b>Compare manual elimination of empty columns via SweetViz to pandas automatic removal</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.columns).difference(df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c95615",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop((df.columns).difference(df_clean.columns), axis = 1)\n",
    "len(df.columns)\n",
    "len(df.columns) == len(df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac07b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fstring\n",
    "__We can remove these columns even though they are not strictly NAN. They are majority NAN and are not useful to the analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d27d19",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Find Columns with Dates and convert them to datetime type</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212933ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_w_dates = df.columns[(df.columns.str.contains('DT', case=False) | df.columns.str.contains('date', case=False) | df.columns.str.contains('OFEPISODE', case=False))] \n",
    "df[cols_w_dates] = df[cols_w_dates].astype('datetime64[s]')\n",
    "cols_w_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58354bdd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Find Columns that contain mixed data types to investigate for possible data quality issues</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mixed_dtypes := {c: dtype for c in df.columns if (dtype := pd.api.types.infer_dtype(df[c])).startswith(\"mixed\")}:\n",
    "    raise TypeError(f\"Dataframe has one more mixed dtypes: {mixed_dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f892cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Run in Linux pd.read_csv was detecting mixed datatype differently than windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Coerce bad columns to int dtype\n",
    "# for col in ['M1311_NSTG_CVRG_SOCROC_E2','M1322_NBR_PRSULC_STG1', 'M2200_THER_NEED_NBR']:\n",
    "#   df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "         \n",
    "# for col in ['M1322_NBR_PRSULC_STG1']:\n",
    "#    df[col] = pd.to_numeric(df[col], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive IDs\n",
    "df.columns[:26]\n",
    "colsMeta = df.columns[:26]\n",
    "# OASIS Factors\n",
    "df.columns[26:]\n",
    "colsOASIS = df.columns[26:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2040678e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <b>Percentage of Null Values by Column to see if there are errors or we can eliminate unhelpful columns</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b9ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[:,colsOASIS].isnull().sum()/len(df.loc[:,colsOASIS])).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eafe464",
   "metadata": {},
   "source": [
    "> Since we previously eliminated completely empty columns we should not expect to see empty columns here. We see the columns ranked by degree of missing values <BR>\n",
    "  Prime candidates for elimination are columns with 90% or greater nulls. We need both training and testing sets to be populated with the same metrics or there is no apples-apples comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f0825",
   "metadata": {},
   "source": [
    "# Part 2 Cleanup of Alive vs Dead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384dbe97",
   "metadata": {},
   "source": [
    "After cleaning up the dataset as a whole, we should dive deeper and cleanup based on the two main types of patients: Alive vs Dead which end up being training and testing sets.  We need a common set of features between both of these groups or we wont have an Apples to Apples comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b078c244",
   "metadata": {},
   "source": [
    "<mark>The dataset contains 3 Patient Groups (Disposition ID): Died in Hospice, Died in Home Health Care, Alive so we now need to move to the 2nd stage of EDA and that is getting a clean deadpatients list</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8c42d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <b>% of null values by Disposition ID</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bef39cc",
   "metadata": {},
   "source": [
    "# Missing Values (Pct Total) for Disposition 3 Patients (Hospice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[:,colsOASIS][df['DispositionId']==3].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==3])).sort_values(ascending=False)\n",
    "mask3 = (df.loc[:,colsOASIS][df['DispositionId']==3].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==3])>=.75).sort_values(ascending=False)\n",
    "#df.loc[:, ~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b0c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,colsOASIS].loc[:, mask3].columns\n",
    "mask3_sr = df.loc[:,colsOASIS].loc[:, mask3].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5437f3fe",
   "metadata": {},
   "source": [
    "# Missing Values (Pct Total) for Disposition 2 Patients (HHG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60482aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[:,colsOASIS][df['DispositionId']==2].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==2])).sort_values(ascending=False)\n",
    "mask2 = (df.loc[:,colsOASIS][df['DispositionId']==2].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==2])>=.75).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5331687",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,colsOASIS].loc[:, mask2].columns\n",
    "mask2_sr = df.loc[:,colsOASIS].loc[:, mask2].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec7edf",
   "metadata": {},
   "source": [
    "# Features Missing All Values for All Dead Patients (Disposition 2 and 3 combined) - We can Eliminate from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mask2_sr.union(mask3_sr))\n",
    "mask2_sr.union(mask3_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a36be29",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e089f9d",
   "metadata": {},
   "source": [
    "# There are no fields completley null for the alive patients cohort except there ae some close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e926104",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[:,colsOASIS][df['DispositionId']==1].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==1])).sort_values(ascending=False)\n",
    "mask1 = (df.loc[:,colsOASIS][df['DispositionId']==1].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==1])>=.75).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigmask = (mask2_sr.union(mask3_sr)).union(df.loc[:,colsOASIS].loc[:, mask1].columns)\n",
    "bigmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b285e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[:,colsOASIS][(df['DispositionId']==2) | (df['DispositionId']==3) ].isnull().sum()/len(df.loc[:,colsOASIS][(df['DispositionId']==2) + (df['DispositionId']==3)])).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d8cece",
   "metadata": {},
   "source": [
    "# Depending on the formula we can wither see True = Column is above threshold, or True if Column is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d1ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullalive = (1-(df.loc[:,colsOASIS][df['DispositionId']==1].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==1]))>=.90).sort_values(ascending=False)\n",
    "emptyalive = (df.loc[:,colsOASIS][df['DispositionId']==1].isnull().sum()/len(df.loc[:,colsOASIS][df['DispositionId']==1])>=.90).sort_values(ascending=False)\n",
    "emptyalive\n",
    "maskfilter1 = emptyalive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eed776",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldead = ((1-(df.loc[:,colsOASIS][(df['DispositionId']==2) | (df['DispositionId']==3) ].isnull().sum())/len(df.loc[:,colsOASIS][(df['DispositionId']==2) + (df['DispositionId']==3)]))>=.90).sort_values(ascending=False)\n",
    "emptydead = (((df.loc[:,colsOASIS][(df['DispositionId']==2) | (df['DispositionId']==3) ].isnull().sum())/len(df.loc[:,colsOASIS][(df['DispositionId']==2) + (df['DispositionId']==3)]))>=.90).sort_values(ascending=False)\n",
    "emptydead\n",
    "maskfilter23 = emptydead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6906701",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[:,colsOASIS].loc[:, maskfilter1].columns)\n",
    "(df.loc[:,colsOASIS].loc[:, maskfilter1].columns)\n",
    "len(df.loc[:,colsOASIS].loc[:, maskfilter23].columns)\n",
    "(df.loc[:,colsOASIS].loc[:, maskfilter23].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len((df.loc[:,colsOASIS].loc[:, maskfilter1].columns).intersection(df.loc[:,colsOASIS].loc[:, maskfilter23].columns))\n",
    "(df.loc[:,colsOASIS].loc[:, maskfilter1].columns).intersection(df.loc[:,colsOASIS].loc[:, maskfilter23].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e32d51",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <b>Dropping Columns that are NULL for Dead Patients</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2339133",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <b>Dropping Columns with too many null values across Dead Patients (Dispo 2 and Dispo 3)</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b81863",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldrop = (df.loc[:,colsOASIS].loc[:, maskfilter23].columns)[:-1].union(bigmask)\n",
    "len(finaldrop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ffae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(finaldrop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2490b40",
   "metadata": {},
   "source": [
    "# Part 2.1 Remove Duplicate Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e411b17",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Rearrange Columns to a more preferable order</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ce8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_w_dates = cols_w_dates.union(df.columns[(df.columns.str.contains('DAYS', case=False))])\n",
    "cols_w_dates = ['epi_SocDate', 'epi_StartOfEpisode', 'epi_EndOfEpisode', 'epi_DischargeDate', 'M0906_DC_TRAN_DTH_DT', 'M0090_INFO_COMPLETED_DT', 'cedd_dateofdeath', 'DaysToDeath']\n",
    "firstcols = [ 'DispositionId', 'pa_id', 'year_born', 'pa_gender', 'epi_id', 'ceo_id']\n",
    "first_cols = firstcols+cols_w_dates\n",
    "move_columns = first_cols + (df.columns.drop(first_cols).tolist())\n",
    "df = df[move_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03093171",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <b>Create Filters that remove the primary keys</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcols_noHIPPS = df.columns.difference(['ceo_HIPPS', 'ceo_HHRG', 'ceo_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a061e8cd",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <b>Remove duplicates while keeping rows that have HIPPS codes</b>\n",
    "</div>\n",
    "\n",
    "#### Sort the Data by CEO_HIPPS with NANS at the bottom, so that when we drop duplicates we keep the first instance with the HIPPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_indx = (df.sort_values(by=\"ceo_HIPPS\", na_position='last').drop_duplicates(subset=dfcols_noHIPPS, keep='first')).index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d2879",
   "metadata": {},
   "source": [
    "#### Creates an index which is the row numbers we want to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d63ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[uniq_indx]\n",
    "len(uniq_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235543ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f380c4",
   "metadata": {},
   "source": [
    "## 2.2 Fix Divergent pa_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeadf296",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <b>Different Patient Id's for the same patient that transferred into Hospice</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc61fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return a boolean series indicating which rows are duplicated and keep both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30643e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df['ceo_id'].duplicated(keep=False)\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de802c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bad4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['ceo_id', 'pa_id'], ascending=[True, True], inplace=True)\n",
    "s = ~df.ceo_id.duplicated(keep='first')\n",
    "df['pa_id'] = df['ceo_id'].map(df[s].set_index('ceo_id')['pa_id'])\n",
    "#df['DaysToDeath'] = df['ceo_id'].map(df[s].set_index('ceo_id')['DaysToDeath'])\n",
    "#df['cedd_dateofdeath'] = df['ceo_id'].map(df[s].set_index('ceo_id')['cedd_dateofdeath'])\n",
    "\n",
    "# s = ~deaddupes2.ceo_id.duplicated()\n",
    "# deaddupes2['pa_id'] = deaddupes2.ceo_id.map(deaddupes2[s].set_index('ceo_id')['pa_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e803f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccc28c8",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <b>Verification that both ceo_id now are correctly labled with one pa_id</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6e5db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtale.show(df[df['ceo_id'] == 140968])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d9f9e",
   "metadata": {},
   "source": [
    "## Fix Duplicate Disposition ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ef1c6",
   "metadata": {},
   "source": [
    "# This group of patients has more than 1 Disposition ID which was discovered when counting the number of unique patient id's in the entire dataset vs the number of unique patients with each disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36445b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many of these will be the same from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df.groupby('pa_id').nunique()['DispositionId'].apply(lambda g: g>1)\n",
    "len(grp[grp].index)\n",
    "grp[grp].index\n",
    "dupedispo = df[df['pa_id'].isin(grp[grp].index)].reset_index(drop=True)\n",
    "dupedispo.to_csv(csvStore+'/duplicate_DispositionIDs.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d2fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(dupedispo.reset_index(drop=True).sort_values(by=['pa_id', 'DispositionId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['pa_id', 'DispositionId'], ascending=[True, True], inplace=True)\n",
    "d = ~df.pa_id.duplicated(keep='last')\n",
    "df['DispositionId'] = df['pa_id'].map(df[d].set_index('pa_id')['DispositionId'])\n",
    "df['DaysToDeath'] = df['pa_id'].map(df[d].set_index('pa_id')['DaysToDeath'])\n",
    "df['cedd_dateofdeath'] = df['pa_id'].map(df[d].set_index('pa_id')['cedd_dateofdeath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df[df.pa_id==56831])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b40b9cf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Export Cleaned DataSet</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d7e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv((csvStore+'/cleaned_data.csv'), sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39755576",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>EDF for our final Factor List</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzing the dataset\n",
    "high_level_cleaned = sv.analyze(df, pairwise_analysis = 'off')\n",
    "#display the report\n",
    "high_level_cleaned .show_html('high_level_cleaned.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb01470",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "  <strong>Create a GPU version of DFF for faster processing</strong> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6289f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = cudf.DataFrame(df)\n",
    "len(dff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a37f071",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "    <b>Tools to Filter DF and understand the dataset</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b53bf5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "    <b>Enumerate the columns to help to more quickly ID them</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6538632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = pd.DataFrame(enumerate(df.columns.values.tolist())).set_index(0)\n",
    "column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed1510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e669a05",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "    <b> Filter Tool to find contents of specific cells</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa16533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[13,107] # add rows if i want to find a specific cell\n",
    "df.iloc[13:14,:10] # add rows if i want to find a specific cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e440811e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "    <b>Eliminate Columns with only 1 distinct value</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1053b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[]\n",
    "for col in df.columns:\n",
    "    if len(df[col].unique()) >= 1 and len(df[col].unique()) <= 3:\n",
    "        cols.append(col)\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72650d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ea23e",
   "metadata": {},
   "source": [
    "The number of unique values in a column provide insight into the nature of the column.<br>\n",
    "The OASIS data is standardized so there are only a few responses the nurses must choose.<br>\n",
    "pa_id will have many more unique value, followed by episode id, all the way to a primary key with a unique value for each row<br>\n",
    "<br>\n",
    "We Eliminated Columns From Dead Patients if all the values were missing.<br>\n",
    "There is no Point in keeping these columns for the independent variables either"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3eb7f9",
   "metadata": {},
   "source": [
    "# Part 3 - Get Patient Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('DispositionId').agg({'pa_id': 'nunique'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf0ab0",
   "metadata": {},
   "source": [
    "> Within each disposition their are a minority of patients who have SOC dates, earlier than their first episode.  Only within the alive patients do we have individual patients with both date types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c4b28f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <b>Get our list of Dead Patients</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qless_than_1yr = '''SELECT pa_id, DaysToDeath, max(JULIANDAY(epi_DischargeDate)) - min(JULIANDAY(epi_SocDate)) as DateDiff\n",
    "           FROM df\n",
    "           WHERE DispositionId != 1\n",
    "           GROUP BY pa_id\n",
    "           HAVING (DateDiff <= 365 AND DaysToDeath <= 365) OR (DateDiff <= 365 AND DaysToDeath IS NULL) OR (DateDiff > 365 AND DaysToDeath <= 365) OR (DateDiff IS NULL AND DaysToDeath <= 365)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df2dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_less_than_1yr = sqldf(qless_than_1yr)\n",
    "deadset = set(sql_less_than_1yr.pa_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67cabbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(deadset) #WHERE (dcc_desc = 'PATIENT EXPIRED' AND dcr_desc = 'PATIENT EXPIRED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac3c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(sql_less_than_1yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dead = df[df.pa_id.isin(deadset)]\n",
    "f\"There are {len(deadset)}, patients who died in less than 1 year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc031ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dead.groupby('DispositionId').agg({'pa_id': 'nunique'})\n",
    "dtale.show(df_dead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543c627e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "    <b>Export Dataset with Bad Columns Removed and Dead Patients with more than 365 days removed</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89467961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dead.to_csv(csvStore+'/dead_patients_final.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a356c1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "    <b>Get our list of Patients who lived longer than 1 year (alive)</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d9f1f6",
   "metadata": {},
   "source": [
    "# Get Patients who have lived longer than 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11f4e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qmore_than_1yr = '''SELECT pa_id, max(JULIANDAY(epi_DischargeDate)) - min(JULIANDAY(epi_SocDate)) as DateDiff\n",
    "           FROM df\n",
    "           GROUP BY pa_id\n",
    "           HAVING (DateDiff > 365 AND DaysToDeath > 365) OR (DateDiff > 365 AND DaysToDeath IS NULL) OR (DateDiff < 365 AND DaysToDeath > 365) OR  (DateDiff IS NULL AND DaysToDeath > 365)'''\n",
    "\n",
    "sql_more_than_1yr = sqldf(qmore_than_1yr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aliveset = set(sql_more_than_1yr.pa_id)\n",
    "df_alive = df[df.pa_id.isin(aliveset)]\n",
    "f\"There are only {len(aliveset)}, patients who have lived longer than 1 year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713bfd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dupes = deadset.intersection(aliveset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c652aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ceaeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.pa_id.isin(dupes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alive.groupby('DispositionId').agg({'pa_id': 'nunique'})\n",
    "dtale.show(df_alive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d4dc9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Export Alive List</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alive.to_csv(csvStore+'/alive_patients_final.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd2f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "neither = deadset.union(aliveset)    \n",
    "conditions = [df['pa_id'].isin(aliveset), df['pa_id'].isin(deadset), (~df['pa_id'].isin(neither))]\n",
    "values = ['0', '1', None]\n",
    "df.insert(2, \"mortality\", np.select(conditions, values))                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d726184",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df.head(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('mortality').agg({'pa_id': 'nunique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7895b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(df[df['mortality'].isnull()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dcde3a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <b>Final Data Sets</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aeabd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[~df['mortality'].isnull()]\n",
    "df_eliminated = df[df['mortality'].isnull()]\n",
    "df_final.to_csv(csvStore+'/final.csv', sep=',', encoding='utf-8', index=False)\n",
    "df_eliminated.to_csv(csvStore+'/eliminated.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54c56c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rapids-22.02]",
   "language": "python",
   "name": "conda-env-rapids-22.02-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
