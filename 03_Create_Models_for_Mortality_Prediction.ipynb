{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df770bea",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Import Packages</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c226b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import os\n",
    "import numpy as np\n",
    "import dtale\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9d0213",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Jupyter Plumbing</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddcf0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load C:\\users\\derek\\.jupyter\\startup.py\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "pd.options.display.max_seq_items = 500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b416a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>View .csv files in our working directory</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59295e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir():\n",
    "    if file.endswith(\".csv\"):\n",
    "        print(os.path.join(\"/\", file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f9b49",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Create df by import .csv files created in previous step</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce16b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients = pd.read_csv('patients.csv')#.iloc[:1000,:]\n",
    "df_episodes = pd.read_csv('df_episode.csv')#.iloc[:150,:]\n",
    "df_visits = pd.read_csv('df_visits.csv')#.iloc[:150,:]\n",
    "df_OASIS = pd.read_csv('df_OASIS.csv')#.iloc[:150,:]\n",
    "df_event_mapping = pd.read_csv('event_mapping_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e3a9d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>This allows us to filter our data to only a handful of patients for testing purposes</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a692fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alive = df_patients[df_patients.mortality==0].pa_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c83cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "alive.dtype\n",
    "len(alive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e226247",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead = df_patients[df_patients.mortality == 1].pa_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d655da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead.dtype\n",
    "len(dead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0cb5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OASIS_dead = df_OASIS[df_OASIS.pa_id.isin(dead)]\n",
    "df_OASIS_dead.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "grpz = df_OASIS_dead.groupby('pa_id').groups\n",
    "#df_OASIS.groupby('pa_id').groups[36796]\n",
    "#df_OASIS.groupby('pa_id').get_group(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grpz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd2f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_most_rows(grpz):\n",
    "    maxcount = max(len(v) for v in grpz.values())\n",
    "    print(f'The max rownum is {maxcount}, and the pa_id is:')\n",
    "    return [k for k, v in grpz.items() if len(v) == maxcount]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5776fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_most_rows(grpz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f912c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_dict = {k: len(v) for k, v in grpz.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082a824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k, v in length_dict.items() if v == max(length_dict.values())]\n",
    "import heapq\n",
    "#[k for k, v in length_dict.items() if v in heapq.nlargest(100, length_dict.values())]\n",
    "dead100 = [k for k, v in length_dict.items() if v in heapq.nlargest(100, length_dict.values())]\n",
    "len(dead100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2411bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_subset = alive.tolist() + dead100\n",
    "len(set(pa_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d4daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a7220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#grpidx = (17191,44654,25607,18808,16862,17018,24556,16274,26475,27968,36781,17747,37870,18011,30512,51094,38501,36509,17716,42124,16950,353347,326385,319247,318537,307867,283257,268061,347156,325432,348164,348170,350202,335984,359871,364367,320405,306152,322487,322263,308977,280963)\n",
    "grpidx = pa_subset\n",
    "#dfidx = np.sort(np.concatenate([df_OASIS.groupby('pa_id').indices[x] for x in grpidx]))\n",
    "#df_OASIS.loc[dfidx, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a733e07",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Repopulate the original df with test data</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients = df_patients[df_patients.pa_id.isin(grpidx)]\n",
    "df_episodes = df_episodes[df_episodes.pa_id.isin(grpidx)]\n",
    "df_visits = df_visits[df_visits.pa_id.isin(grpidx)]\n",
    "df_OASIS = df_OASIS[df_OASIS.pa_id.isin(grpidx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e22b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OASIS.pa_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a4167",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <b>View datatypes - the int64 were causing a bug when serializing to JSON</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ebcd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients.dtypes#.head()\n",
    "df_episodes.dtypes#.head()\n",
    "df_visits.dtypes#.head()\n",
    "df_OASIS.dtypes#.head()\n",
    "df_event_mapping.dtypes#.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2cb8f8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Import packages needed to Parallel process the Data</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae21c7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>View the number of cores recognized for parallel processing</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(joblib.cpu_count() - 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cfc682",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Import pyhealth classes and functions</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d536c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.data.base_mimic import parallel_parse_tables\n",
    "from pyhealth.utils.utility_parallel import unfold_parallel\n",
    "from pyhealth.utils.utility_parallel import partition_estimators\n",
    "from pyhealth.utils.utility import read_csv_to_df\n",
    "from pyhealth.utils.utility import make_dirs_if_not_exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd73fe4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Create Output Directory to Save Files</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b51d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pathlib import Path\n",
    "#Path(\"pyhealth_export\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489478c3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Setup the Parallel Proccesing Workflow</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3989ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './pyhealth_export3'\n",
    "n_jobz = (joblib.cpu_count() - 4)  # number of parallel jobs\n",
    "duration = 21600  # time window for episode generation\n",
    "selection_method = 'last'\n",
    "var_list = df_event_mapping.OASIS.tolist()\n",
    "patient_id_list = df_patients['pa_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event_mapping.iloc[-1]['OASIS']\n",
    "df_event_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772d3fe0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <b>Custom JSON Encoder to deal with np.int64 serialization Bug</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693323b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a8ef91",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Execute the Data Processing</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd52d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patients_list, starts, n_jobs = partition_estimators(\n",
    "        len(patient_id_list), n_jobs=n_jobz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15151460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patient_id_list\n",
    "n_patients_list # you can see the batch being separates\n",
    "starts # cummulative sum of number of jobs\n",
    "n_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700de1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.data.base_mimic import parallel_parse_tables\n",
    "all_results = Parallel(n_jobs=n_jobs, max_nbytes=None, verbose=True)(\n",
    "delayed(parallel_parse_tables)(\n",
    "     patient_df=df_patients,\n",
    "     admission_df=df_episodes,\n",
    "      icu_df=df_visits,\n",
    "     event_df=df_OASIS,\n",
    "     event_mapping_df=df_event_mapping,\n",
    "     duration=duration,\n",
    "     save_dir=save_dir,selection_method = selection_method, var_list = var_list, patient_id_list = patient_id_list)\n",
    " for i in range(n_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783b49f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data_loc = os.path.join(save_dir, 'patient_data_demo.json')\n",
    "all_results = list(map(list, zip(*all_results)))\n",
    "valid_data_list = unfold_parallel(all_results[0], n_jobs)\n",
    "valid_id_list = unfold_parallel(all_results[1], n_jobs)\n",
    "\n",
    "patient_data_list = []\n",
    "for p in valid_data_list:\n",
    "        patient_data_list.append(p.data)\n",
    "\n",
    "with open(patient_data_loc, 'w') as outfile:\n",
    "        json.dump(patient_data_list, outfile, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d519fd5e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <b>Examination of the Output</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patient_data_loc\n",
    "#all_results\n",
    "#type(valid_data_list[2])   # WHY ARE THESE INTEGERS IN THIS LIST\n",
    "#valid_data_list[0].data\n",
    "#valid_id_list[0].data\n",
    "#patient_data_list[0]\n",
    "valid_id_list\n",
    "valid_data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c62a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3405682",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_results[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ea66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37417040",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_results[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3fb8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_results[0][0][0].data['dob'])\n",
    "#all_results[0][0][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44dd94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[0][0][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf5cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f54f92",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Generate Labels for Mortality or Not</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f40fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open(patient_data_loc) as f:\n",
    "        patient_data_list = json.load(f)\n",
    "\n",
    "    ##########################################################\n",
    "    output_headers = ['episode_file', 'death_indicator']\n",
    "\n",
    "    output_df = pd.DataFrame(columns=output_headers)\n",
    "\n",
    "    # for i, p_id in tqdm(enumerate(patient_data_list), total=len(patient_data_list)):\n",
    "    for i, p_id in enumerate(tqdm(patient_data_list)):\n",
    "        for adm in p_id['admission_list']:\n",
    "            # csv file does not exist\n",
    "            if 'episode_csv' in adm.keys():\n",
    "                temp_list = [adm['episode_csv'], adm['death_indicator']]\n",
    "\n",
    "                # append to the major episode dataframe\n",
    "                temp_df = pd.DataFrame(temp_list).transpose()\n",
    "                temp_df.columns = output_headers\n",
    "                output_df = pd.concat([output_df, temp_df], axis=0)\n",
    "\n",
    "    # change file header to lower case\n",
    "    output_df.columns = output_df.columns.str.lower()\n",
    "    output_df.to_csv(\n",
    "        os.path.join(save_dir, 'y_mortality_mimic_demo.csv'),\n",
    "        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25286913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3dd705",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir\n",
    "data_dir = os.path.join(root_dir, 'pyhealth_export3')\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb3c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b99d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.data.expdata_generator import sequencedata as expdata_generator\n",
    "from pyhealth.evaluation.evaluator import func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ade80",
   "metadata": {},
   "outputs": [],
   "source": [
    "### May choose any of these models\n",
    "# from pyhealth.models.sequence.dipole import Dipole as model\n",
    "from pyhealth.models.sequence.lstm import LSTM as model\n",
    "#from pyhealth.models.sequence.gru import GRU as GRU\n",
    "# from pyhealth.models.sequence.embedgru import EmbedGRU as model\n",
    "# from pyhealth.models.sequence.retain import Retain as model\n",
    "# from pyhealth.models.sequence.raim import RAIM as model\n",
    "# from pyhealth.models.sequence.tlstm import tLSTM as model\n",
    "# from pyhealth.models.sequence.xgboost import XGBoostECG as model\n",
    "# from pyhealth.models.sequence.rf import RandomForest as model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root_dir, 'pyhealth_export')\n",
    "expdata_id = '2020.0810.data.mortality.mimic'\n",
    "\n",
    "    # set up the datasets\n",
    "cur_dataset = expdata_generator(expdata_id, root_dir=root_dir)\n",
    "cur_dataset.get_exp_data(sel_task='mortality', data_root=data_dir)\n",
    "cur_dataset.load_exp_data()\n",
    "cur_dataset.show_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e47420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d85853",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "    # initialize the model for training\n",
    "    # turn on GPU by setting use_gpu to True\n",
    "expmodel_id = '2020.0810.gru.data.mortality.mimic.gpu'\n",
    "clf = model(expmodel_id=expmodel_id, n_batchsize=20, use_gpu=False,\n",
    "                n_epoch=50, gpu_ids='0, 1')\n",
    "clf.fit(cur_dataset.train, cur_dataset.valid)\n",
    "\n",
    "    # load the best model for inference\n",
    "clf.load_model()\n",
    "clf.inference(cur_dataset.test)\n",
    "pred_results = clf.get_results()\n",
    "print(pred_results['hat_y'])\n",
    "\n",
    "# evaluate the model\n",
    "r = func(pred_results['hat_y'], pred_results['y'])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded36fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dataset.train\n",
    "cur_dataset.valid\n",
    "cur_dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.inference(cur_dataset.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa938215",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91aaab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae04aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyhealth]",
   "language": "python",
   "name": "conda-env-pyhealth-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
